{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing \n",
    "import math\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import matthews_corrcoef, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the training data, kindly change the path according to your file\n",
    "train_data = pd.read_csv('train_upd.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating the feature : avg_data_speed (Find description in report)\n",
    "train_data['total_bytes'] = 0\n",
    "byte_cols = ['web_browsing_total_bytes',\n",
    " 'video_total_bytes',\n",
    " 'social_ntwrking_bytes',\n",
    " 'cloud_computing_total_bytes',\n",
    " 'web_security_total_bytes',\n",
    " 'gaming_total_bytes',\n",
    " 'health_total_bytes',\n",
    " 'communication_total_bytes',\n",
    " 'file_sharing_total_bytes',\n",
    " 'remote_access_total_bytes',\n",
    " 'photo_sharing_total_bytes',\n",
    " 'software_dwnld_total_bytes',\n",
    " 'marketplace_total_bytes',\n",
    " 'storage_services_total_bytes',\n",
    " 'audio_total_bytes',\n",
    " 'location_services_total_bytes',\n",
    " 'presence_total_bytes',\n",
    " 'advertisement_total_bytes',\n",
    " 'system_total_bytes',\n",
    " 'voip_total_bytes',\n",
    " 'speedtest_total_bytes',\n",
    " 'email_total_bytes',\n",
    " 'weather_total_bytes',\n",
    " 'media_total_bytes',\n",
    " 'mms_total_bytes',\n",
    " 'others_total_bytes']\n",
    "train_data['speed'] = 0\n",
    "for i in byte_cols:\n",
    "    train_data['total_bytes'] += train_data[i]\n",
    "train_data.speed = (train_data.total_bytes/(train_data.par_min*train_data.subscriber_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding the vendor data\n",
    "train_data.ran_vendor.replace({'NOKIA':1,'ERICSSON':2,'HUAWEI':3},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating the new feature : week_day ( find desciption in report)\n",
    "temp =[]\n",
    "for i in range(len(train_data)):\n",
    "    temp.append(datetime.datetime(train_data['par_year'][i],train_data['par_month'][i],train_data['par_day'][i]).weekday())\n",
    "train_data[\"week_day\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the target variable\n",
    "y = train_data.copy()\n",
    "y = y[\"Congestion_Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#because par_year and par_month features were useless we are dropping them\n",
    "#also par_day feature is already converted into week_day\n",
    "x1=train_data.drop(['par_year','par_month','par_day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropping the target variable from the data\n",
    "x = x1.drop(['Congestion_Type'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "#dropping the cell name from X_train but we are keeping cell name in x2 for future merging use\n",
    "x2 = X_train.copy()\n",
    "X_train.drop(['cell_name'],axis = 1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the first step of two step model,here we convert the problem into binary classification by converting\n",
    "#all the not-NC target rows into 'C'\n",
    "y2 = y_train.copy()\n",
    "y_train[y_train == \"4G_BACKHAUL_CONGESTION\"] = \"C\"\n",
    "y_train[y_train == \"4G_RAN_CONGESTION\"] = \"C\"\n",
    "y_train[y_train == \"3G_BACKHAUL_CONGESTION\"] = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#encoding the y_train into 0,1\n",
    "le = preprocessing.LabelEncoder()\n",
    "mvar47 = le.fit_transform(y_train.astype(str))\n",
    "y_train = mvar47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.486152+0.00698812\ttrain-error:0.183549+0.000245231\ttest-MCC:0.48318+0.0105985\ttest-error:0.18462+0.00160011\n",
      "[50]\ttrain-MCC:0.850405+0.00160637\ttrain-error:0.056215+0.000514387\ttest-MCC:0.829794+0.00638507\ttest-error:0.0637888+0.00234391\n",
      "[100]\ttrain-MCC:0.879619+0.00146734\ttrain-error:0.0458302+0.000534293\ttest-MCC:0.851305+0.00582669\ttest-error:0.0564538+0.00214296\n",
      "[150]\ttrain-MCC:0.889174+0.00160302\ttrain-error:0.0422713+0.000559299\ttest-MCC:0.85856+0.00594968\ttest-error:0.0537485+0.00222036\n",
      "[200]\ttrain-MCC:0.894866+0.00173414\ttrain-error:0.0401075+0.000646861\ttest-MCC:0.861293+0.0061075\ttest-error:0.0527622+0.00228978\n",
      "[250]\ttrain-MCC:0.898211+0.00153135\ttrain-error:0.0388343+0.000567994\ttest-MCC:0.861258+0.00592105\ttest-error:0.0527145+0.00216163\n",
      "[300]\ttrain-MCC:0.900922+0.00153287\ttrain-error:0.0377897+0.000574558\ttest-MCC:0.861942+0.0057464\ttest-error:0.0524437+0.00213889\n",
      "[350]\ttrain-MCC:0.903466+0.00150801\ttrain-error:0.0368033+0.000575655\ttest-MCC:0.8616+0.00584267\ttest-error:0.0525712+0.00213802\n",
      "[400]\ttrain-MCC:0.906189+0.00167366\ttrain-error:0.0357582+0.000644536\ttest-MCC:0.863502+0.00528345\ttest-error:0.0518075+0.00193408\n",
      "[450]\ttrain-MCC:0.908533+0.00163987\ttrain-error:0.0348567+0.000625448\ttest-MCC:0.862797+0.00503457\ttest-error:0.052046+0.00185674\n",
      "[500]\ttrain-MCC:0.910864+0.00139159\ttrain-error:0.0339547+0.000532692\ttest-MCC:0.863356+0.004976\ttest-error:0.051855+0.00181612\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-aff8f676a6da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'eta'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'objective'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'binary:logistic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'silent'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'n_thread'\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmy_scorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatthews_corrcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mxgbcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaximize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    443\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    444\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[1;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1045\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#this is the xgboost crossvalidation for determining the best learning rate and n_round/n_estimators\n",
    "#we define a custom metric function mat, which gives us the MCC cross-validation score\n",
    "\n",
    "threshold = 0.5\n",
    "def mat(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'MCC', matthews_corrcoef(labels, preds > threshold)\n",
    "dtrain = xgb.DMatrix(X_train,label = y_train)\n",
    "\n",
    "#this gives us the cross-validation search\n",
    "param = {'max_depth':3, 'eta':0.1,'objective':'binary:logistic','silent':1,'n_thread' :4}\n",
    "\n",
    "#we create a custom scorer which gives us the cross-validation MCC\n",
    "my_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "#the cross-validation process starts here, this code will take time to run\n",
    "xgbcv = xgb.cv(param,dtrain,num_boost_round=1500,nfold = 4,verbose_eval = 50,feval = mat,maximize = True )\n",
    "\n",
    "#we found best cross-validation MCC for eta/learning_rate = 0.1 and n_boost_round/n_estimators = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed: 17.3min\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed: 20.7min\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed: 23.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=4, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'subsample': [0.2, 0.4, 0.6, 0.8, 1], 'colsample_bytree': [0.2, 0.4, 0.6, 0.8, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "#now we do grid search for tuning parameters other than eta and n_round namely subsample,colsample_bytree,max_depth,min_child_weight\n",
    "\n",
    "#this is our paramter grid for the grid search\n",
    "param_test1 = {'subsample':[0.2,0.4,0.6,0.8,1],'colsample_bytree':[0.2,0.4,0.6,0.8,1],'max_depth':[2,3,4,5,6,7],'min_child_weight' : [2,3,4,5,6,7]}\n",
    "\n",
    "#this is the grid search function,it will provide us the best cross-validation MCC for the grid. It will take time to run\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=900,gamma=0,objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "param_grid = param_test1, scoring=my_scorer,n_jobs=4,iid=False, cv=4,verbose = 10)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "\n",
    "#we found the best parameters to be colsample_bytree=1 ,min_child_weight=4, subsample=1, max_depth=2\n",
    "#Cross validation MCC for model1 =  86.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsearch1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-b66293e8b9fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gsearch1' is not defined"
     ]
    }
   ],
   "source": [
    "#prints the best params\n",
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fitting an Xgboost model with the best found parameters\n",
    "xgb1 = xgb.XGBClassifier(booster='gbtree', colsample_bylevel=1,\n",
    "    colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
    "    max_delta_step=0, max_depth=2, min_child_weight=4, missing=None,\n",
    "    n_estimators=900, n_jobs=3, nthread=1, objective='multi:softmax',\n",
    "    random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "    seed=None, subsample=1, num_class = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=4, missing=None, n_estimators=900,\n",
       "       n_jobs=3, nthread=1, num_class=2, objective='multi:softmax',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting model on training data\n",
    "xgb1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new data with only the congestion target for training\n",
    "new_data = x2[y2!= 'NC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating only congestion target variable\n",
    "y2 = y2[y2!= \"NC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding into 0,1,2\n",
    "le = preprocessing.LabelEncoder()\n",
    "mvar47 = le.fit_transform(y2.astype(str))\n",
    "y2 = mvar47\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-MCC:0.365691+0.00475269\ttrain-merror:0.428314+0.00432515\ttest-MCC:0.346448+0.00834121\ttest-merror:0.441004+0.00704769\n",
      "[50]\ttrain-MCC:0.72599+0.00162118\ttrain-merror:0.183673+0.00114577\ttest-MCC:0.651312+0.00457876\ttest-merror:0.233454+0.0030945\n",
      "[100]\ttrain-MCC:0.766429+0.00135166\ttrain-merror:0.156026+0.000910178\ttest-MCC:0.679774+0.00478287\ttest-merror:0.213696+0.00325228\n",
      "[150]\ttrain-MCC:0.785286+0.000801388\ttrain-merror:0.143421+0.000548677\ttest-MCC:0.689474+0.00418408\ttest-merror:0.207167+0.00282601\n",
      "[200]\ttrain-MCC:0.797419+0.00118776\ttrain-merror:0.135318+0.000806677\ttest-MCC:0.694093+0.00587931\ttest-merror:0.204084+0.00395866\n",
      "[250]\ttrain-MCC:0.807342+0.00168688\ttrain-merror:0.128697+0.00114088\ttest-MCC:0.696611+0.00583214\ttest-merror:0.202403+0.00392799\n",
      "[300]\ttrain-MCC:0.816658+0.00208667\ttrain-merror:0.12248+0.00140676\ttest-MCC:0.696975+0.00616976\ttest-merror:0.202148+0.00414608\n",
      "[350]\ttrain-MCC:0.824046+0.00158547\ttrain-merror:0.117546+0.00107845\ttest-MCC:0.697704+0.00559586\ttest-merror:0.201659+0.00376174\n",
      "[400]\ttrain-MCC:0.832168+0.00181921\ttrain-merror:0.112122+0.0012316\ttest-MCC:0.697494+0.00502292\ttest-merror:0.201786+0.00337656\n",
      "[450]\ttrain-MCC:0.83993+0.00207246\ttrain-merror:0.106933+0.00139395\ttest-MCC:0.697122+0.00559515\ttest-merror:0.20202+0.0037732\n",
      "[500]\ttrain-MCC:0.847546+0.00215804\ttrain-merror:0.10185+0.00144991\ttest-MCC:0.696541+0.00566221\ttest-merror:0.202403+0.00382025\n",
      "[550]\ttrain-MCC:0.856221+0.00173598\ttrain-merror:0.0960585+0.00116813\ttest-MCC:0.697368+0.00595013\ttest-merror:0.20185+0.00400453\n",
      "[600]\ttrain-MCC:0.863868+0.0023893\ttrain-merror:0.0909543+0.00160778\ttest-MCC:0.695788+0.00531136\ttest-merror:0.202892+0.00358143\n",
      "[650]\ttrain-MCC:0.872105+0.0019739\ttrain-merror:0.0854528+0.00132958\ttest-MCC:0.695273+0.00534548\ttest-merror:0.203233+0.00360884\n",
      "[700]\ttrain-MCC:0.880281+0.00247053\ttrain-merror:0.0799942+0.00166119\ttest-MCC:0.695356+0.00627294\ttest-merror:0.203169+0.00421979\n"
     ]
    }
   ],
   "source": [
    "#tuning the eta and n_round for 2nd model like the 1st one\n",
    "def mat(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'MCC', matthews_corrcoef(labels, preds)\n",
    "dtrain = xgb.DMatrix(new_data.loc[:, new_data.columns != 'cell_name'],label = y2)\n",
    "\n",
    "\n",
    "param = {'max_depth':4, 'eta':0.1,'objective':'multi:softmax','silent':1,'n_thread' :4,'num_class':3}\n",
    "my_scorer = make_scorer(matthews_corrcoef)\n",
    "xgbcv = xgb.cv(param,dtrain,num_boost_round=850,nfold = 4,verbose_eval = 50,feval = mat,maximize = True )\n",
    "\n",
    "#we found the best eta = 0.1 and n_boost_round = 850"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed: 19.5min\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed: 26.4min\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 30.0min\n"
     ]
    }
   ],
   "source": [
    "#setting up the tuning grid\n",
    "my_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "param_test1 = {'subsample':[0.2,0.4,0.6,0.8,1],'colsample_bytree':[0.2,0.4,0.6,0.8,1],'max_depth':[2,3,4,5,6,7],'min_child_weight' : [2,3,4,5,6,7]}\n",
    "gsearch1 = GridSearchCV(estimator = xgb.XGBClassifier( learning_rate =0.1, n_estimators=850,gamma=0, max_depth=2, min_child_weight=4,\n",
    "objective= 'multi:softmax', nthread=4, scale_pos_weight=1, seed=27), \n",
    "param_grid = param_test1, scoring=my_scorer,n_jobs=4,iid=False, cv=4,verbose = 10)\n",
    "gsearch1.fit(new_data.loc[:, new_data.columns != 'cell_name'],y2)\n",
    "\n",
    "#we found the best parameters to be colsample_bytree=0.2 ,min_child_weight=4, subsample=0.6, max_depth=2\n",
    "#Cross validation MCC for model2 =  70.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is the second model which is capable of predicting 0,1,2 for different congestion types (3g,4g-ran and 4g-backhaul)\n",
    "xgb2 = xgb.XGBClassifier(booster='gbtree', colsample_bylevel=1,\n",
    "    colsample_bytree=0.2, gamma=0, learning_rate=0.1,\n",
    "    max_delta_step=0, max_depth=2, min_child_weight=4, missing=None,\n",
    "    n_estimators=850, n_jobs=3, nthread=1, objective='multi:softmax',\n",
    "    random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "    seed=None, subsample=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.2, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=4, missing=None, n_estimators=850,\n",
       "       n_jobs=3, nthread=1, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.6)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting on training data for second model\n",
    "xgb2.fit(new_data.loc[:, new_data.columns != 'cell_name'],y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encoding the 20% target variable(testing)\n",
    "le = preprocessing.LabelEncoder()\n",
    "mvar47 = le.fit_transform(y_test.astype(str))\n",
    "y_test = mvar47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the C vs NC on test data using model1\n",
    "pred1_test = xgb1.predict(X_test.loc[:, X_test.columns != 'cell_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of cell names with congestion = NC\n",
    "l = X_test[pred1_test == 1]['cell_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataframe of cell_name of NCs and Predictions which is equal to 3 for NC (using inverse tranformation of encoder)\n",
    "df = pd.DataFrame(l)\n",
    "df['cell_name'] = df[0]\n",
    "df.head()\n",
    "df.drop(0,inplace = True,axis =1)\n",
    "df['Predictions'] = 3\n",
    "dfnew = pd.merge(X_test,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of cellname with congestion = C\n",
    "l2 =X_test[pred1_test == 0]['cell_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new testing data with only congestion = C\n",
    "new_test = X_test[pred1_test == 0]\n",
    "new_test1 = new_test.drop(['cell_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on the data with congestion = C to further classify it into 3g,4g-ran,4g-backhaul\n",
    "pred2_test = xgb2.predict(new_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4702: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#using encoder inverse transform we know that 3g : 0 , 4g_backhaul : 1, 4g_ran :2 , NC : 3\n",
    "new_test['Predictions'] = 10000 # initializing the column\n",
    "new_test['Predictions'][pred2_test == 0] = 0\n",
    "new_test['Predictions'][pred2_test == 1] = 1\n",
    "new_test['Predictions'][pred2_test == 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concating the two dataframes which have predictions for NC(dfnew) and different classes of C(new_test1)\n",
    "iopp = pd.concat([dfnew,new_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sorting by cell name\n",
    "iopp = iopp.sort_values(by = 'cell_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test1 = y_test1.sort_values(by = 'cell_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_name</th>\n",
       "      <th>4G_rat</th>\n",
       "      <th>par_hour</th>\n",
       "      <th>par_min</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>web_browsing_total_bytes</th>\n",
       "      <th>video_total_bytes</th>\n",
       "      <th>social_ntwrking_bytes</th>\n",
       "      <th>cloud_computing_total_bytes</th>\n",
       "      <th>web_security_total_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>mms_total_bytes</th>\n",
       "      <th>others_total_bytes</th>\n",
       "      <th>beam_direction</th>\n",
       "      <th>cell_range</th>\n",
       "      <th>tilt</th>\n",
       "      <th>ran_vendor</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>total_bytes_mod</th>\n",
       "      <th>week_day</th>\n",
       "      <th>True_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60240</th>\n",
       "      <td>260006</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1128</td>\n",
       "      <td>1009</td>\n",
       "      <td>206</td>\n",
       "      <td>602</td>\n",
       "      <td>414</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38308</th>\n",
       "      <td>395468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>823</td>\n",
       "      <td>68220</td>\n",
       "      <td>31059</td>\n",
       "      <td>4187</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>110272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19851</th>\n",
       "      <td>412780</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>609</td>\n",
       "      <td>62</td>\n",
       "      <td>1491</td>\n",
       "      <td>1837</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28602</th>\n",
       "      <td>442738</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>487</td>\n",
       "      <td>93</td>\n",
       "      <td>432</td>\n",
       "      <td>12760</td>\n",
       "      <td>182</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42517</th>\n",
       "      <td>476133</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1291</td>\n",
       "      <td>1973</td>\n",
       "      <td>9308</td>\n",
       "      <td>514</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_name  4G_rat  par_hour  par_min  subscriber_count  \\\n",
       "60240     260006       1         4       30              1128   \n",
       "38308     395468       0        11       35               823   \n",
       "19851     412780       0         6       60               609   \n",
       "28602     442738       1        10       35               487   \n",
       "42517     476133       0         2       55                 8   \n",
       "\n",
       "       web_browsing_total_bytes  video_total_bytes  social_ntwrking_bytes  \\\n",
       "60240                      1009                206                    602   \n",
       "38308                     68220              31059                   4187   \n",
       "19851                        62               1491                   1837   \n",
       "28602                        93                432                  12760   \n",
       "42517                      1291               1973                   9308   \n",
       "\n",
       "       cloud_computing_total_bytes  web_security_total_bytes     ...       \\\n",
       "60240                          414                        36     ...        \n",
       "38308                          238                         3     ...        \n",
       "19851                           36                         8     ...        \n",
       "28602                          182                        23     ...        \n",
       "42517                          514                        58     ...        \n",
       "\n",
       "       mms_total_bytes  others_total_bytes  beam_direction  cell_range  tilt  \\\n",
       "60240               66                 172              74           6     4   \n",
       "38308               11                 165             119           5     2   \n",
       "19851                5                  37             117           6     3   \n",
       "28602               18                  95             110           2     2   \n",
       "42517               37                   7              79           3     2   \n",
       "\n",
       "       ran_vendor  total_bytes  total_bytes_mod  week_day  True_Values  \n",
       "60240           3         4279              0.0         6            0  \n",
       "38308           3       110272              0.0         4            1  \n",
       "19851           1        12133              0.0         2            0  \n",
       "28602           2        19402              0.0         4            3  \n",
       "42517           2        22142              0.0         0            1  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_name</th>\n",
       "      <th>4G_rat</th>\n",
       "      <th>par_hour</th>\n",
       "      <th>par_min</th>\n",
       "      <th>subscriber_count</th>\n",
       "      <th>web_browsing_total_bytes</th>\n",
       "      <th>video_total_bytes</th>\n",
       "      <th>social_ntwrking_bytes</th>\n",
       "      <th>cloud_computing_total_bytes</th>\n",
       "      <th>web_security_total_bytes</th>\n",
       "      <th>...</th>\n",
       "      <th>mms_total_bytes</th>\n",
       "      <th>others_total_bytes</th>\n",
       "      <th>beam_direction</th>\n",
       "      <th>cell_range</th>\n",
       "      <th>tilt</th>\n",
       "      <th>ran_vendor</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>total_bytes_mod</th>\n",
       "      <th>week_day</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60240</th>\n",
       "      <td>260006</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>1128</td>\n",
       "      <td>1009</td>\n",
       "      <td>206</td>\n",
       "      <td>602</td>\n",
       "      <td>414</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>172</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38308</th>\n",
       "      <td>395468</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>823</td>\n",
       "      <td>68220</td>\n",
       "      <td>31059</td>\n",
       "      <td>4187</td>\n",
       "      <td>238</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>110272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3925</th>\n",
       "      <td>412780</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>609</td>\n",
       "      <td>62</td>\n",
       "      <td>1491</td>\n",
       "      <td>1837</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "      <td>117</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>442738</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>487</td>\n",
       "      <td>93</td>\n",
       "      <td>432</td>\n",
       "      <td>12760</td>\n",
       "      <td>182</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42517</th>\n",
       "      <td>476133</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "      <td>1291</td>\n",
       "      <td>1973</td>\n",
       "      <td>9308</td>\n",
       "      <td>514</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cell_name  4G_rat  par_hour  par_min  subscriber_count  \\\n",
       "60240     260006       1         4       30              1128   \n",
       "38308     395468       0        11       35               823   \n",
       "3925      412780       0         6       60               609   \n",
       "3097      442738       1        10       35               487   \n",
       "42517     476133       0         2       55                 8   \n",
       "\n",
       "       web_browsing_total_bytes  video_total_bytes  social_ntwrking_bytes  \\\n",
       "60240                      1009                206                    602   \n",
       "38308                     68220              31059                   4187   \n",
       "3925                         62               1491                   1837   \n",
       "3097                         93                432                  12760   \n",
       "42517                      1291               1973                   9308   \n",
       "\n",
       "       cloud_computing_total_bytes  web_security_total_bytes     ...       \\\n",
       "60240                          414                        36     ...        \n",
       "38308                          238                         3     ...        \n",
       "3925                            36                         8     ...        \n",
       "3097                           182                        23     ...        \n",
       "42517                          514                        58     ...        \n",
       "\n",
       "       mms_total_bytes  others_total_bytes  beam_direction  cell_range  tilt  \\\n",
       "60240               66                 172              74           6     4   \n",
       "38308               11                 165             119           5     2   \n",
       "3925                 5                  37             117           6     3   \n",
       "3097                18                  95             110           2     2   \n",
       "42517               37                   7              79           3     2   \n",
       "\n",
       "       ran_vendor  total_bytes  total_bytes_mod  week_day  Predictions  \n",
       "60240           3         4279              0.0         6            0  \n",
       "38308           3       110272              0.0         4            1  \n",
       "3925            1        12133              0.0         2            3  \n",
       "3097            2        19402              0.0         4            3  \n",
       "42517           2        22142              0.0         0            0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iopp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7376531938076256"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the matthews coef:\n",
    "matthews_corrcoef(y_test1['True_Values'],iopp['Predictions'])\n",
    "\n",
    "#by running all this code 5 times with different training and testing data(we did not fix random state while splitting)\n",
    "#we got the average MCC to be 0.7395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the final testing file we have to predict\n",
    "finaltest = pd.read_csv('test_upd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating respective features which were made in training and other preprocessing\n",
    "finaltest['total_bytes'] = 0\n",
    "byte_cols = ['web_browsing_total_bytes',\n",
    " 'video_total_bytes',\n",
    " 'social_ntwrking_bytes',\n",
    " 'cloud_computing_total_bytes',\n",
    " 'web_security_total_bytes',\n",
    " 'gaming_total_bytes',\n",
    " 'health_total_bytes',\n",
    " 'communication_total_bytes',\n",
    " 'file_sharing_total_bytes',\n",
    " 'remote_access_total_bytes',\n",
    " 'photo_sharing_total_bytes',\n",
    " 'software_dwnld_total_bytes',\n",
    " 'marketplace_total_bytes',\n",
    " 'storage_services_total_bytes',\n",
    " 'audio_total_bytes',\n",
    " 'location_services_total_bytes',\n",
    " 'presence_total_bytes',\n",
    " 'advertisement_total_bytes',\n",
    " 'system_total_bytes',\n",
    " 'voip_total_bytes',\n",
    " 'speedtest_total_bytes',\n",
    " 'email_total_bytes',\n",
    " 'weather_total_bytes',\n",
    " 'media_total_bytes',\n",
    " 'mms_total_bytes',\n",
    " 'others_total_bytes']\n",
    "finaltest['total_bytes_mod'] = 0\n",
    "for i in byte_cols:\n",
    "    finaltest['total_bytes'] += finaltest[i]\n",
    "finaltest.total_bytes_mod = (finaltest.total_bytes_mod/(finaltest.par_min*finaltest.subscriber_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaltest.ran_vendor.replace({'NOKIA':1,'ERICSSON':2,'HUAWEI':3},inplace=True)\n",
    "import datetime\n",
    "temp =[]\n",
    "for i in range(len(finaltest)):\n",
    "    temp.append(datetime.datetime(finaltest['par_year'][i],finaltest['par_month'][i],finaltest['par_day'][i]).weekday())\n",
    "finaltest[\"week_day\"] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaltest = finaltest.drop(['par_year','par_month','par_day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting the C vs NC using model1\n",
    "finalpred1 = xgb1.predict(finaltest.loc[:, finaltest.columns != 'cell_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of cellnames with NC\n",
    "lfinal = finaltest[finalpred1 == 1]['cell_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#similar to inhouse testing\n",
    "dffinal = pd.DataFrame(lfinal)\n",
    "dffinal['cell_name'] = dffinal[0]\n",
    "dffinal.head()\n",
    "dffinal.drop(0,inplace = True,axis =1)\n",
    "dffinal['Predictions'] = 3\n",
    "dffinalnew = pd.merge(finaltest,dffinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of cellnames with C\n",
    "l2final = finaltest[finalpred1 == 0]['cell_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#taking only that data which our model1 predicted to be a congestion\n",
    "new_test_final = finaltest[finalpred1 == 0]\n",
    "new_test1_final = new_test_final.drop(['cell_name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting the congestion type\n",
    "finalpred2 = xgb2.predict(new_test1_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6262"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding encoded variable to a new dataframe\n",
    "new_test_past['Predictions'] = 10000\n",
    "new_test_past['Predictions'][past_pred2 == 0] = 0\n",
    "new_test_past['Predictions'][past_pred2 == 1] = 1\n",
    "new_test_past['Predictions'][past_pred2 == 2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concating the predictions for both C vs NC and different types of C\n",
    "iopp = pd.concat([dffinalnew,new_test_final])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the final submission file\n",
    "submission = pd.merge(finaltest,iopp[['cell_name','Predictions']],on = 'cell_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission[['cell_name','Predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Congestion_Type'] = submission['Predictions']\n",
    "submission.drop('Predictions',axis =1 ,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse transforming the labeled data\n",
    "submission['Congestion_Type'] = le.inverse_transform(submission['Congestion_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing to csv\n",
    "submission.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the next few cells will deal with the plots we created for the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_round</th>\n",
       "      <th>train_MCC</th>\n",
       "      <th>test_MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.850405</td>\n",
       "      <td>0.829794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>0.851305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>0.889174</td>\n",
       "      <td>0.858560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>0.894866</td>\n",
       "      <td>0.861293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0.898211</td>\n",
       "      <td>0.861258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_round  train_MCC  test_MCC\n",
       "0       50   0.850405  0.829794\n",
       "1      100   0.879619  0.851305\n",
       "2      150   0.889174  0.858560\n",
       "3      200   0.894866  0.861293\n",
       "4      250   0.898211  0.861258"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is the plot for xgboost cross-validation run to tune eta and n_round\n",
    "\n",
    "train_MCC = [0.850405,0.879619,0.889174,0.894866,0.898211,0.900922,0.903466,0.906189,0.908533,0.910864]\n",
    "test_MCC = [0.829794,0.851305,0.85856,0.861293,0.861258,0.861942,0.8616,0.863502,0.862797,0.863356]\n",
    "nround = [50,100,150,200,250,300,350,400,450,500]\n",
    "n_chart = pd.DataFrame(nround)\n",
    "n_chart.columns = ['n_round']\n",
    "n_chart['train_MCC'] = train_MCC\n",
    "n_chart['test_MCC'] = test_MCC\n",
    "n_chart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e502ba6dd8>]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.plot(n_chart['n_round'],n_chart['train_MCC'])\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "plt.plot(n_chart['n_round'],n_chart['test_MCC'])\n",
    "plt.savefig('tuning.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the code to generate correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e500f0af98>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_name = x.copy()\n",
    "corr = x_name.corr()\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.savefig('corr_plot.jpg')\n",
    "\n",
    "#Please check the foler you're running this script in to find the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#next one is the xgboost feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = xgb1.feature_importances_\n",
    "imp = imp*1000\n",
    "\n",
    "col_names = ['cell_name' , 'par_hour', 'par_min', 'subscriber_count', 'web_browsing_total_bytes', 'video_total_bytes', 'social_ntwrking_bytes', 'cloud_computing_total_bytes', 'web_security_total_bytes', 'gaming_total_bytes', 'health_total_bytes', 'communication_total_bytes', 'file_sharing_total_bytes', 'remote_access_total_bytes', 'photo_sharing_total_bytes', 'software_dwnld_total_bytes', 'marketplace_total_bytes', 'storage_services_total_bytes', 'audio_total_bytes', 'location_services_total_bytes', 'presence_total_bytes', 'advertisement_total_bytes', 'system_total_bytes', 'voip_total_bytes', 'speedtest_total_bytes', 'email_total_bytes', 'weather_total_bytes', 'media_total_bytes', 'mms_total_bytes', 'others_total_bytes', 'beam_direction', 'cell_range', 'tilt', 'total_bytes', 'speed', 'week_day', 'service']\n",
    "chart = pd.DataFrame(col_names)\n",
    "chart['imp'] = imp\n",
    "chart.columns = ['Feature_Name','Feature_Importance']\n",
    "\n",
    "chart = chart.sort_values(by=['Feature_Importance'], ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "plt.title('Feature importance plot')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature Name')\n",
    "ax = sns.barplot(x=chart['Feature_Importance'], y=chart['Feature_Name'])\n",
    "plt.savefig('Final_plot.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
